#    accelerate launch --mixed_precision bf16 scripts/train_zimage_v2.py --config configs/current_training.toml

import os
import sys
import argparse
import logging
import signal
from pathlib import Path

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "../src"))

import torch
import torch.nn.functional as F
from tqdm import tqdm
from accelerate import Accelerator
from accelerate.utils import set_seed
from diffusers.optimization import get_scheduler

# Local imports
from zimage_trainer.networks.lora import LoRANetwork, ZIMAGE_TARGET_NAMES, ZIMAGE_ADALN_NAMES, EXCLUDE_PATTERNS
from zimage_trainer.dataset.dataloader import create_dataloader, create_reg_dataloader, get_reg_config
from zimage_trainer.acrf_trainer import ACRFTrainer
from zimage_trainer.utils.snr_utils import compute_snr_weights
from zimage_trainer.utils.l2_scheduler import L2RatioScheduler, create_l2_scheduler_from_args
from zimage_trainer.utils.timestep_aware_loss import TimestepAwareLossScheduler, create_timestep_aware_scheduler_from_args
from zimage_trainer.losses.frequency_aware_loss import FrequencyAwareLoss
from zimage_trainer.losses.style_structure_loss import LatentStyleStructureLoss

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Interrupt handler
_interrupted = False

def signal_handler(signum, frame):
    global _interrupted
    _interrupted = True
    logger.info("[INTERRUPT] Training will stop after current step...")

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)


def parse_args():
    parser = argparse.ArgumentParser(description="Z-Image AC-RF Training")
    parser.add_argument("--config", type=str, required=True, help="TOML config path")
    
    # Model
    parser.add_argument("--dit", type=str, default=None)
    parser.add_argument("--vae", type=str, default=None)
    
    # Training
    parser.add_argument("--output_dir", type=str, default="output")
    parser.add_argument("--output_name", type=str, default=None)
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--num_train_epochs", type=int, default=None)
    parser.add_argument("--learning_rate", type=float, default=None)
    parser.add_argument("--gradient_accumulation_steps", type=int, default=1)
    parser.add_argument("--max_grad_norm", type=float, default=1.0)
    parser.add_argument("--save_every_n_epochs", type=int, default=None)
    parser.add_argument("--gradient_checkpointing", type=bool, default=True)
    
    # LoRA
    parser.add_argument("--network_dim", type=int, default=16)
    parser.add_argument("--network_alpha", type=float, default=16)
    parser.add_argument("--resume_lora", type=str, default=None,
        help="ç»§ç»­è®­ç»ƒçš„ LoRA è·¯å¾„ (.safetensors)ï¼ŒRank å°†ä»æ–‡ä»¶è‡ªåŠ¨æ¨æ–­")
    
    # AC-RF / Turbo
    parser.add_argument("--turbo_steps", type=int, default=10)
    parser.add_argument("--shift", type=float, default=3.0)
    parser.add_argument("--jitter_scale", type=float, default=0.02)
    parser.add_argument("--latent_jitter_scale", type=float, default=0.01)
    
    # SNR
    parser.add_argument("--snr_gamma", type=float, default=5.0)
    parser.add_argument("--snr_floor", type=float, default=0.1)
    
    # Loss weights
    parser.add_argument("--lambda_l1", type=float, default=1.0)
    parser.add_argument("--lambda_cosine", type=float, default=0.0)
    parser.add_argument("--enable_freq", type=bool, default=True)
    parser.add_argument("--lambda_freq", type=float, default=0.3)
    parser.add_argument("--alpha_hf", type=float, default=1.0)
    parser.add_argument("--beta_lf", type=float, default=0.2)
    parser.add_argument("--enable_style", type=bool, default=True)
    parser.add_argument("--lambda_style", type=float, default=0.3)
    parser.add_argument("--lambda_struct", type=float, default=1.0)
    
    # Style-structure sub-params
    parser.add_argument("--lambda_light", type=float, default=0.5)
    parser.add_argument("--lambda_color", type=float, default=0.3)
    parser.add_argument("--lambda_tex", type=float, default=0.5)
    
    # Curvature Penalty (æ›²ç‡æƒ©ç½š - é¼“åŠ±æ›´ç›´çš„è½¨è¿¹)
    parser.add_argument("--enable_curvature", type=bool, default=False,
        help="å¯ç”¨æ›²ç‡æƒ©ç½š (é¼“åŠ±é”šç‚¹é—´åŒ€é€Ÿç›´çº¿è¿åŠ¨)")
    parser.add_argument("--lambda_curvature", type=float, default=0.05,
        help="æ›²ç‡æƒ©ç½šæƒé‡")
    parser.add_argument("--curvature_interval", type=int, default=10,
        help="æ¯ N æ­¥è®¡ç®—ä¸€æ¬¡æ›²ç‡æƒ©ç½š (å‡å°‘è®¡ç®—å¼€é”€)")
    parser.add_argument("--curvature_start_epoch", type=int, default=0,
        help="ä»ç¬¬ N ä¸ª epoch å¼€å§‹å¯ç”¨æ›²ç‡æƒ©ç½š")
    
    # Drop Text (ä¿æŒä½ CFG èƒ½åŠ›)
    parser.add_argument("--drop_text_ratio", type=float, default=0.0,
        help="ä¸¢å¼ƒæ–‡æœ¬æ¡ä»¶çš„æ¦‚ç‡ (ä¿æŒä½ CFG èƒ½åŠ›)ï¼Œæ¨è 0.1")
    
    # Memory optimization
    parser.add_argument("--blocks_to_swap", type=int, default=0)
    parser.add_argument("--block_swap_enabled", type=bool, default=False)
    
    # Turbo / RAFT mode
    parser.add_argument("--enable_turbo", type=bool, default=True)
    parser.add_argument("--raft_mode", type=bool, default=False)
    parser.add_argument("--free_stream_ratio", type=float, default=0.3)
    
    # L2 Ratio Schedule
    parser.add_argument("--l2_schedule_mode", type=str, default="constant",
        choices=["constant", "linear_increase", "linear_decrease", "step"],
        help="L2 ratio è°ƒåº¦æ¨¡å¼")
    parser.add_argument("--l2_initial_ratio", type=float, default=None,
        help="L2 èµ·å§‹æ¯”ä¾‹ (é»˜è®¤ä½¿ç”¨ free_stream_ratio)")
    parser.add_argument("--l2_final_ratio", type=float, default=None,
        help="L2 ç»“æŸæ¯”ä¾‹")
    parser.add_argument("--l2_milestones", type=str, default="",
        help="é˜¶æ¢¯æ¨¡å¼åˆ‡æ¢ç‚¹ (epoch, é€—å·åˆ†éš”)")
    parser.add_argument("--l2_include_anchor", type=bool, default=False,
        help="L2 åŒæ—¶è®¡ç®—é”šç‚¹æ—¶é—´æ­¥")
    parser.add_argument("--l2_anchor_ratio", type=float, default=0.3,
        help="L2 é”šç‚¹æ—¶é—´æ­¥æƒé‡ (ä»…å½“ include_anchor=True æ—¶ç”Ÿæ•ˆ)")
    
    # æ—¶é—´æ­¥æ„ŸçŸ¥ Loss æƒé‡
    parser.add_argument("--enable_timestep_aware_loss", type=bool, default=False,
        help="å¯ç”¨æ—¶é—´æ­¥åˆ†åŒºåŠ¨æ€ Loss æƒé‡")
    parser.add_argument("--timestep_high_threshold", type=float, default=0.7,
        help="é«˜å™ªå£°åŒºé˜ˆå€¼ (Ïƒ > æ­¤å€¼æ—¶é‡ç»“æ„)")
    parser.add_argument("--timestep_low_threshold", type=float, default=0.3,
        help="ä½å™ªå£°åŒºé˜ˆå€¼ (Ïƒ < æ­¤å€¼æ—¶é‡çº¹ç†)")
    
    # LoRA é«˜çº§é€‰é¡¹
    parser.add_argument("--train_adaln", type=bool, default=False,
        help="è®­ç»ƒ AdaLN è°ƒåˆ¶å±‚ (æ¿€è¿›æ¨¡å¼)")
    
    # Optimizer
    parser.add_argument("--optimizer_type", type=str, default="AdamW8bit")
    parser.add_argument("--weight_decay", type=float, default=0.0)
    
    # Scheduler
    parser.add_argument("--lr_scheduler", type=str, default="cosine_with_restarts")
    parser.add_argument("--lr_warmup_steps", type=int, default=100)
    parser.add_argument("--lr_num_cycles", type=int, default=1)
    
    args = parser.parse_args()
    
    # Load config from TOML
    if args.config:
        import toml
        config = toml.load(args.config)
        
        # Apply config values
        model_cfg = config.get("model", {})
        training_cfg = config.get("training", {})
        lora_cfg = config.get("lora", {})
        acrf_cfg = config.get("acrf", {})
        advanced_cfg = config.get("advanced", {})
        
        # Model
        args.dit = model_cfg.get("dit", args.dit)
        args.vae = model_cfg.get("vae", args.vae)
        args.output_dir = model_cfg.get("output_dir", args.output_dir)
        
        # Training
        if args.output_name is None:
            args.output_name = training_cfg.get("output_name", "zimage_lora")
            
        if args.num_train_epochs is None:
            args.num_train_epochs = training_cfg.get("num_train_epochs", 
                                    advanced_cfg.get("num_train_epochs", 10))
                                    
        if args.learning_rate is None:
            args.learning_rate = training_cfg.get("learning_rate", 1e-4)

        args.gradient_accumulation_steps = training_cfg.get("gradient_accumulation_steps",
                                            advanced_cfg.get("gradient_accumulation_steps", args.gradient_accumulation_steps))
        
        # Seed (ä» [training] æˆ– [advanced] è¯»å–)
        args.seed = training_cfg.get("seed", advanced_cfg.get("seed", args.seed))
                                            
        if args.save_every_n_epochs is None:
            args.save_every_n_epochs = advanced_cfg.get("save_every_n_epochs", 1)
            
        args.gradient_checkpointing = training_cfg.get("gradient_checkpointing",
                                        advanced_cfg.get("gradient_checkpointing", args.gradient_checkpointing))
        
        # LoRA
        args.network_dim = lora_cfg.get("network_dim", args.network_dim)
        args.network_alpha = lora_cfg.get("network_alpha", args.network_alpha)
        args.resume_lora = lora_cfg.get("resume_lora", args.resume_lora)
        
        # AC-RF
        args.turbo_steps = acrf_cfg.get("turbo_steps", args.turbo_steps)
        args.shift = acrf_cfg.get("shift", args.shift)
        args.jitter_scale = acrf_cfg.get("jitter_scale", args.jitter_scale)
        args.latent_jitter_scale = acrf_cfg.get("latent_jitter_scale", args.latent_jitter_scale)
        
        # SNR
        args.snr_gamma = training_cfg.get("snr_gamma", acrf_cfg.get("snr_gamma", args.snr_gamma))
        args.snr_floor = acrf_cfg.get("snr_floor", args.snr_floor)
        
        # Loss
        args.lambda_l1 = training_cfg.get("lambda_l1", args.lambda_l1)
        args.lambda_cosine = training_cfg.get("lambda_cosine", args.lambda_cosine)
        args.enable_freq = training_cfg.get("enable_freq", args.enable_freq)
        args.lambda_freq = training_cfg.get("lambda_freq", args.lambda_freq)
        args.alpha_hf = training_cfg.get("alpha_hf", args.alpha_hf)
        args.beta_lf = training_cfg.get("beta_lf", args.beta_lf)
        args.enable_style = training_cfg.get("enable_style", args.enable_style)
        args.lambda_style = training_cfg.get("lambda_style", args.lambda_style)
        args.lambda_struct = training_cfg.get("lambda_struct", args.lambda_struct)
        # Style-structure sub-params
        args.lambda_light = training_cfg.get("lambda_light", args.lambda_light)
        args.lambda_color = training_cfg.get("lambda_color", args.lambda_color)
        args.lambda_tex = training_cfg.get("lambda_tex", args.lambda_tex)
        
        # Memory
        args.blocks_to_swap = advanced_cfg.get("blocks_to_swap", args.blocks_to_swap)
        args.block_swap_enabled = args.blocks_to_swap > 0
        
        # Turbo / RAFT mode
        args.enable_turbo = acrf_cfg.get("enable_turbo", args.enable_turbo)
        args.raft_mode = acrf_cfg.get("raft_mode", args.raft_mode)
        args.free_stream_ratio = acrf_cfg.get("free_stream_ratio", args.free_stream_ratio)
        
        # L2 Schedule
        args.l2_schedule_mode = acrf_cfg.get("l2_schedule_mode", args.l2_schedule_mode)
        args.l2_initial_ratio = acrf_cfg.get("l2_initial_ratio", args.l2_initial_ratio)
        args.l2_final_ratio = acrf_cfg.get("l2_final_ratio", args.l2_final_ratio)
        args.l2_milestones = acrf_cfg.get("l2_milestones", args.l2_milestones)
        args.l2_include_anchor = acrf_cfg.get("l2_include_anchor", args.l2_include_anchor)
        args.l2_anchor_ratio = acrf_cfg.get("l2_anchor_ratio", args.l2_anchor_ratio)
        
        # Curvature Penalty (æ›²ç‡æƒ©ç½š)
        args.enable_curvature = acrf_cfg.get("enable_curvature", getattr(args, 'enable_curvature', False))
        args.lambda_curvature = acrf_cfg.get("lambda_curvature", getattr(args, 'lambda_curvature', 0.05))
        args.curvature_interval = acrf_cfg.get("curvature_interval", getattr(args, 'curvature_interval', 10))
        args.curvature_start_epoch = acrf_cfg.get("curvature_start_epoch", getattr(args, 'curvature_start_epoch', 0))
        
        # Timestep-aware Loss
        args.enable_timestep_aware_loss = acrf_cfg.get("enable_timestep_aware_loss", 
                                          training_cfg.get("enable_timestep_aware_loss", args.enable_timestep_aware_loss))
        args.timestep_high_threshold = acrf_cfg.get("timestep_high_threshold", args.timestep_high_threshold)
        args.timestep_low_threshold = acrf_cfg.get("timestep_low_threshold", args.timestep_low_threshold)
        
        # LoRA é«˜çº§é€‰é¡¹
        lora_cfg = config.get("lora", {})
        args.train_adaln = lora_cfg.get("train_adaln", args.train_adaln)
        
        # Optimizer
        args.optimizer_type = training_cfg.get("optimizer_type", args.optimizer_type)
        args.weight_decay = training_cfg.get("weight_decay", args.weight_decay)
        
        # Scheduler
        args.lr_scheduler = training_cfg.get("lr_scheduler", args.lr_scheduler)
        args.lr_warmup_steps = training_cfg.get("lr_warmup_steps", args.lr_warmup_steps)
        args.lr_num_cycles = training_cfg.get("lr_num_cycles", args.lr_num_cycles)
        
    return args


def main():
    global _interrupted
    args = parse_args()
    
    # Create output directory
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Initialize Accelerator
    accelerator = Accelerator(
        gradient_accumulation_steps=args.gradient_accumulation_steps,
    )
    
    if args.seed is not None:
        set_seed(args.seed)
    
    # Determine weight dtype
    weight_dtype = torch.float32
    if accelerator.mixed_precision == "fp16":
        weight_dtype = torch.float16
    elif accelerator.mixed_precision == "bf16":
        weight_dtype = torch.bfloat16
    
    logger.info("\n" + "=" * 60)
    logger.info("ğŸš€ Z-Image AC-RF Training")
    logger.info("=" * 60)
    
    # åŸºæœ¬ä¿¡æ¯
    logger.info(f"ğŸ“ è¾“å‡º: {args.output_dir}/{args.output_name}")
    logger.info(f"ğŸ¯ æ¨¡å¼: {'Turbo (' + str(args.turbo_steps) + ' steps)' if args.enable_turbo else 'æ ‡å‡† Flow Matching'}")
    logger.info(f"âš¡ ç²¾åº¦: {weight_dtype}")
    
    # è®­ç»ƒå‚æ•°
    logger.info(f"\nğŸ“‹ è®­ç»ƒå‚æ•°:")
    logger.info(f"   Epochs: {args.num_train_epochs} | LR: {args.learning_rate} | Grad Accum: {args.gradient_accumulation_steps}")
    logger.info(f"   LoRA: rank={args.network_dim}, alpha={args.network_alpha}")
    logger.info(f"   Optimizer: {args.optimizer_type} | Scheduler: {args.lr_scheduler}")
    
    # AC-RF å‚æ•°
    logger.info(f"\nâš™ï¸ AC-RF å‚æ•°:")
    logger.info(f"   Shift: {args.shift} | Jitter: {args.jitter_scale} | Latent Jitter: {args.latent_jitter_scale}")
    logger.info(f"   SNR Gamma: {args.snr_gamma} | SNR Floor: {args.snr_floor}")
    if args.raft_mode:
        logger.info(f"   RAFT: ON (L2 ratio={args.free_stream_ratio})")
    
    # Loss é…ç½®
    loss_cfg = f"L1Ã—{args.lambda_l1} + CosÃ—{args.lambda_cosine}"
    if args.enable_freq:
        loss_cfg += f" + FreqÃ—{args.lambda_freq}(hf={args.alpha_hf},lf={args.beta_lf})"
    if args.enable_style:
        loss_cfg += f" + StyleÃ—{args.lambda_style}"
    logger.info(f"\nğŸ“Š Loss é…ç½®:")
    logger.info(f"   {loss_cfg}")
    if getattr(args, 'enable_timestep_aware_loss', False):
        logger.info(f"   ğŸ› æ—¶é—´æ­¥æ„ŸçŸ¥: ON (æ—©æœŸé‡ç»“æ„, åæœŸé‡çº¹ç†)")
    if getattr(args, 'enable_curvature', False):
        logger.info(f"   ğŸ”„ æ›²ç‡æƒ©ç½š: ON (Î»={getattr(args, 'lambda_curvature', 0.05)}, interval={getattr(args, 'curvature_interval', 10)}, start_epoch={getattr(args, 'curvature_start_epoch', 0)})")
    
    logger.info("\n[1/7] åŠ è½½ Transformer...")
    
    try:
        from zimage_trainer.models.transformer_z_image import ZImageTransformer2DModel
        logger.info("  âœ“ ä½¿ç”¨æœ¬åœ° ZImageTransformer2DModel")
    except ImportError:
        from diffusers import ZImageTransformer2DModel
        logger.warning("  âš  ä½¿ç”¨ diffusers é»˜è®¤ç‰ˆæœ¬")
    
    transformer = ZImageTransformer2DModel.from_pretrained(
        args.dit,
        torch_dtype=weight_dtype,
        local_files_only=True,
    )
    transformer = transformer.to(accelerator.device)
    
    # Enable gradient checkpointing (BEFORE freeze)
    if args.gradient_checkpointing:
        transformer.enable_gradient_checkpointing()
        logger.info("  [CKPT] Gradient checkpointing enabled")
    
    transformer.train()
    
    # =========================================================================
    # 2. Block Swapper (çœŸæ­£çš„å—äº¤æ¢)
    # =========================================================================
    block_swapper = None
    if args.blocks_to_swap > 0:
        from zimage_trainer.utils.block_swapper import create_block_swapper
        logger.info(f"\n[SWAP] Initializing Block Swapper (blocks_to_swap={args.blocks_to_swap})...")
        block_swapper = create_block_swapper(
            blocks_to_swap=args.blocks_to_swap,
            device=accelerator.device,
            verbose=True,
        )
        # è®¾ç½®å—äº¤æ¢å™¨åˆ°æ¨¡å‹
        transformer.set_block_swapper(block_swapper)
        logger.info("  [OK] Block Swapper attached to transformer")
    
    # =========================================================================
    # 3. Apply LoRA with proper dtype
    # =========================================================================
    
    # ç»§ç»­è®­ç»ƒæ¨¡å¼ï¼šä»å·²æœ‰ LoRA æ–‡ä»¶æ¨æ–­ rank
    if args.resume_lora and os.path.exists(args.resume_lora):
        logger.info(f"\n[RESUME] ç»§ç»­è®­ç»ƒæ¨¡å¼: {args.resume_lora}")
        from safetensors.torch import load_file
        state_dict = load_file(args.resume_lora)
        # ä»æƒé‡æ¨æ–­ rank (æ‰¾ç¬¬ä¸€ä¸ª lora_down æƒé‡)
        for key, value in state_dict.items():
            if "lora_down" in key and value.dim() == 2:
                args.network_dim = value.shape[0]  # down çš„ out_features å°±æ˜¯ rank
                logger.info(f"  [RESUME] ä»æƒé‡æ¨æ–­ rank = {args.network_dim}")
                break
        else:
            logger.warning("  [RESUME] æ— æ³•æ¨æ–­ rankï¼Œä½¿ç”¨é»˜è®¤å€¼")
    
    logger.info("\n[2/7] åˆ›å»º LoRA (rank={args.network_dim})...")
    
    # åŠ¨æ€æ„å»º target_names å’Œ exclude_patterns
    target_names = list(ZIMAGE_TARGET_NAMES)
    exclude_patterns = list(EXCLUDE_PATTERNS)
    
    train_adaln = getattr(args, 'train_adaln', False)
    # ç¡®ä¿ train_adaln æ˜¯å¸ƒå°”å€¼ (TOML å¯èƒ½è¿”å›å­—ç¬¦ä¸²)
    if isinstance(train_adaln, str):
        train_adaln = train_adaln.lower() in ('true', '1', 'yes')
    train_adaln = bool(train_adaln)
    
    if train_adaln:
        target_names.extend(ZIMAGE_ADALN_NAMES)
        exclude_patterns = [p for p in exclude_patterns if "adaLN" not in p]
        logger.info("  [LoRA] AdaLN è®­ç»ƒå·²å¯ç”¨")
    
    network = LoRANetwork(
        unet=transformer,
        lora_dim=args.network_dim,
        alpha=args.network_alpha,
        multiplier=1.0,
        target_names=target_names,
        exclude_patterns=exclude_patterns,
    )
    network.apply_to(transformer)
    
    # ç»§ç»­è®­ç»ƒæ¨¡å¼ï¼šåŠ è½½å·²æœ‰æƒé‡
    if args.resume_lora and os.path.exists(args.resume_lora):
        network.load_weights(args.resume_lora)
        logger.info(f"  [RESUME] å·²åŠ è½½ LoRA æƒé‡: {os.path.basename(args.resume_lora)}")
    
    # CRITICAL: Convert LoRA params to same dtype as model (BF16)
    network.to(accelerator.device, dtype=weight_dtype)
    
    # Freeze base model (LoRA params remain trainable)
    transformer.requires_grad_(False)
    
    # Get only LoRA trainable params
    trainable_params = []
    for lora_module in network.lora_modules.values():
        trainable_params.extend(lora_module.get_trainable_params())
    
    param_count = sum(p.numel() for p in trainable_params)
    logger.info(f"  âœ“ å‚æ•°é‡: {param_count:,} ({param_count/1e6:.2f}M)")
    
    # =========================================================================
    # 4. AC-RF Trainer
    # =========================================================================
    logger.info("\n[3/7] åˆå§‹åŒ– AC-RF Trainer...")
    acrf_trainer = ACRFTrainer(
        num_train_timesteps=1000,
        turbo_steps=args.turbo_steps,
        shift=args.shift,
    )
    acrf_trainer.verify_setup()
    
    # =========================================================================
    # 5. Loss Functions
    # =========================================================================
    logger.info("\n[4/7] åˆå§‹åŒ– Loss å‡½æ•°...")
    
    freq_loss_fn = None
    if args.enable_freq:
        freq_loss_fn = FrequencyAwareLoss(
            alpha_hf=args.alpha_hf,
            beta_lf=args.beta_lf,
        )
    
    style_loss_fn = None
    if args.enable_style:
        style_loss_fn = LatentStyleStructureLoss(
            lambda_struct=args.lambda_struct,
            lambda_light=args.lambda_light,
            lambda_color=args.lambda_color,
            lambda_tex=args.lambda_tex,
        )
    
    # RAFT L2 æ··åˆæ¨¡å¼
    if isinstance(args.raft_mode, str):
        args.raft_mode = args.raft_mode.lower() in ('true', '1', 'yes')
    args.raft_mode = bool(args.raft_mode)
    
    # æ—¶é—´æ­¥æ„ŸçŸ¥ Loss æƒé‡è°ƒåº¦å™¨
    timestep_aware_scheduler = create_timestep_aware_scheduler_from_args(args)
    
    # =========================================================================
    # 6. DataLoader
    # =========================================================================
    logger.info("\n[5/7] åŠ è½½æ•°æ®é›†...")
    args.dataset_config = args.config
    dataloader = create_dataloader(args)
    logger.info(f"  âœ“ {len(dataloader)} batches")
    
    # æ­£åˆ™æ•°æ®é›†åŠ è½½ (é˜²æ­¢è¿‡æ‹Ÿåˆ)
    reg_dataloader = create_reg_dataloader(args)
    reg_config = get_reg_config(args)
    reg_iterator = None
    if reg_dataloader:
        reg_weight = reg_config.get('weight', 1.0)
        reg_ratio = reg_config.get('ratio', 0.5)
        logger.info(f"  + æ­£åˆ™æ•°æ®é›†: {len(reg_dataloader)} batches")
    else:
        reg_weight = 0.0
        reg_ratio = 0.0
    
    # =========================================================================
    # 7. Optimizer and Scheduler
    # =========================================================================
    logger.info("\n[6/7] é…ç½®ä¼˜åŒ–å™¨...")
    logger.info(f"  âœ“ {args.optimizer_type}, LR={args.learning_rate}")
    
    if args.optimizer_type == "AdamW8bit":
        try:
            import bitsandbytes as bnb
            optimizer = bnb.optim.AdamW8bit(trainable_params, lr=args.learning_rate, weight_decay=args.weight_decay)
        except ImportError:
            optimizer = torch.optim.AdamW(trainable_params, lr=args.learning_rate, weight_decay=args.weight_decay)
            logger.warning("  âš  bitsandbytes æœªå®‰è£…ï¼Œä½¿ç”¨æ ‡å‡† AdamW")
    elif args.optimizer_type == "Adafactor":
        from transformers.optimization import Adafactor
        optimizer = Adafactor(
            trainable_params, lr=args.learning_rate, weight_decay=args.weight_decay,
            scale_parameter=False, relative_step=False
        )
    else:  # AdamW
        optimizer = torch.optim.AdamW(trainable_params, lr=args.learning_rate, weight_decay=args.weight_decay)
    
    # Prepare with accelerator FIRST (before calculating steps)
    optimizer, dataloader, lr_scheduler_placeholder = accelerator.prepare(
        optimizer, dataloader, None
    )
    
    # Calculate max_train_steps AFTER prepare (len(dataloader) is already divided by num_gpus)
    max_train_steps = len(dataloader) * args.num_train_epochs // args.gradient_accumulation_steps
    
    lr_scheduler = get_scheduler(
        args.lr_scheduler,
        optimizer=optimizer,
        num_warmup_steps=args.lr_warmup_steps,
        num_training_steps=max_train_steps,
        num_cycles=args.lr_num_cycles,
    )
    
    logger.info(f"  âœ“ è®­ç»ƒè½®æ•°: {args.num_train_epochs}, æ€»æ­¥æ•°: {max_train_steps}")
    
    # =========================================================================
    # 8. Training Loop
    # =========================================================================
    logger.info("\n[7/7] å¼€å§‹è®­ç»ƒ...")
    logger.info("=" * 60)
    
    # åˆ›å»º L2 è°ƒåº¦å™¨
    l2_scheduler = create_l2_scheduler_from_args(args)
    
    global_step = 0
    micro_step = 0  # å®é™… batch è®¡æ•°å™¨ï¼ˆç”¨äºæ›²ç‡æƒ©ç½šé—´éš”ï¼‰
    ema_loss = None
    ema_decay = 0.99
    last_curv_loss = 0.0  # æŒä¹…åŒ–æ›²ç‡å€¼ï¼ˆæ‰“å°æ—¶ä½¿ç”¨ï¼‰
    
    # Loss ç´¯ç§¯å˜é‡ï¼ˆTensorBoard æ ‡å‡†åšæ³•ï¼‰
    accumulated_loss = 0.0
    accumulated_l1 = 0.0
    accumulated_cos = 0.0
    accumulated_freq = 0.0
    accumulated_style = 0.0
    accumulated_l2 = 0.0
    accumulation_count = 0
    
    for epoch in range(args.num_train_epochs):
        if _interrupted:
            logger.info("[EXIT] Training interrupted by user")
            # ç´§æ€¥ä¿å­˜å½“å‰æƒé‡
            if accelerator.is_main_process and global_step > 0:
                emergency_path = Path(args.output_dir) / f"{args.output_name}_interrupted_step{global_step}.safetensors"
                network.save_weights(str(emergency_path), dtype=weight_dtype)
                logger.info(f"[SAVE] Emergency checkpoint saved: {emergency_path}")
            break
        
        # è·å–å½“å‰ epoch çš„ L2 ratio
        current_l2_ratio = l2_scheduler.get_ratio(epoch + 1) if l2_scheduler else getattr(args, 'free_stream_ratio', 0.3)
        
        # åªåœ¨ RAFT æ¨¡å¼å¯ç”¨æ—¶æ˜¾ç¤º L2 ratio
        if args.raft_mode:
            logger.info(f"\nEpoch {epoch + 1}/{args.num_train_epochs} [L2={current_l2_ratio:.2f}]")
        else:
            logger.info(f"\nEpoch {epoch + 1}/{args.num_train_epochs}")
        
        for step, batch in enumerate(tqdm(dataloader, desc=f"Epoch {epoch+1}", disable=True)):
            if _interrupted:
                # ä¸­é€”ä¸­æ–­ï¼Œä¿å­˜å½“å‰è¿›åº¦
                if accelerator.is_main_process and global_step > 0:
                    emergency_path = Path(args.output_dir) / f"{args.output_name}_interrupted_step{global_step}.safetensors"
                    network.save_weights(str(emergency_path), dtype=weight_dtype)
                    logger.info(f"[SAVE] Emergency checkpoint saved: {emergency_path}")
                break
                
            # æ–°å¢: æ£€æŸ¥ batch æ˜¯å¦ä¸º Noneï¼Œé¿å… 'NoneType' object is not subscriptable é”™è¯¯
            if batch is None:
                logger.warning(f"[WARNING] Skipping None batch at step {step} in epoch {epoch + 1}")
                continue
                    
            with accelerator.accumulate(transformer):
                # Get data
                latents = batch['latents'].to(accelerator.device, dtype=weight_dtype)
                vl_embed = batch['vl_embed']
                vl_embed = [v.to(accelerator.device, dtype=weight_dtype) for v in vl_embed]
                
                batch_size = latents.shape[0]
                
                # === Drop Text (ä¿æŒä½ CFG èƒ½åŠ›) ===
                # ä»¥ä¸€å®šæ¦‚ç‡ä¸¢å¼ƒæ–‡æœ¬æ¡ä»¶ï¼Œè®©æ¨¡å‹å­¦ä¹ æ— æ¡ä»¶ç”Ÿæˆæ–°é£æ ¼
                drop_text_ratio = getattr(args, 'drop_text_ratio', 0.0)
                if drop_text_ratio > 0 and torch.rand(1).item() < drop_text_ratio:
                    # åˆ›å»ºç©ºæ–‡æœ¬åµŒå…¥ (å…¨é›¶æˆ–å¾ˆå°çš„å€¼)
                    vl_embed = [torch.zeros_like(v) for v in vl_embed]
                
                # Generate noise
                noise = torch.randn_like(latents)
                
                # AC-RF sampling (timestep with jitter)
                # use_anchor=True: Turbo é”šç‚¹é‡‡æ ·, use_anchor=False: æ ‡å‡† Flow Matching
                noisy_latents, timesteps, target_velocity = acrf_trainer.sample_batch(
                    latents, noise, jitter_scale=args.jitter_scale, use_anchor=args.enable_turbo
                )
                
                # Latent jitter (optional)
                if args.latent_jitter_scale > 0:
                    latent_jitter = torch.randn_like(noisy_latents) * args.latent_jitter_scale
                    noisy_latents = noisy_latents + latent_jitter
                    target_velocity = noise - latents
                
                # Prepare model input - Z-Image expects List[Tensor(C, 1, H, W)]
                model_input = noisy_latents.unsqueeze(2)
                
                # CRITICAL: For frozen model + checkpointing, input must have requires_grad=True
                if args.gradient_checkpointing:
                    model_input.requires_grad_(True)
                
                model_input_list = list(model_input.unbind(dim=0))
                
                # Timestep normalization (Z-Image uses (1000-t)/1000)
                timesteps_normalized = (1000 - timesteps) / 1000.0
                timesteps_normalized = timesteps_normalized.to(dtype=weight_dtype)
                
                # Forward pass
                model_pred_list = transformer(
                    x=model_input_list,
                    t=timesteps_normalized,
                    cap_feats=vl_embed,
                )[0]
                
                # Stack outputs
                model_pred = torch.stack(model_pred_list, dim=0)
                model_pred = model_pred.squeeze(2)
                
                # Z-Image output is negated
                model_pred = -model_pred
                
                # =========================================================
                # Compute Losses
                # =========================================================
                
                # è·å–æ—¶é—´æ­¥æ„ŸçŸ¥æƒé‡ (å¦‚æœå¯ç”¨)
                ts_weights = None
                if timestep_aware_scheduler:
                    ts_weights = timestep_aware_scheduler.get_mean_weights(timesteps, num_train_timesteps=1000)
                
                # L1 Loss
                l1_loss_val = F.l1_loss(model_pred, target_velocity)
                loss = args.lambda_l1 * l1_loss_val
                loss_components = {'l1': l1_loss_val.item()}
                
                # Cosine Loss
                cos_loss_val = 0.0
                if args.lambda_cosine > 0:
                    cos_loss = 1 - F.cosine_similarity(
                        model_pred.flatten(1), target_velocity.flatten(1), dim=1
                    ).mean()
                    loss = loss + args.lambda_cosine * cos_loss
                    cos_loss_val = cos_loss.item()
                loss_components['cosine'] = cos_loss_val
                
                # Frequency Loss (requires noisy_latents and timesteps)
                # åº”ç”¨æ—¶é—´æ­¥æ„ŸçŸ¥æƒé‡ç¼©æ”¾
                freq_loss_val = 0.0
                if freq_loss_fn and args.lambda_freq > 0:
                    freq_loss = freq_loss_fn(model_pred, target_velocity, noisy_latents, timesteps, num_train_timesteps=1000)
                    freq_scale = ts_weights['lambda_freq_scale'] if ts_weights else 1.0
                    loss = loss + args.lambda_freq * freq_scale * freq_loss
                    freq_loss_val = freq_loss.item()
                loss_components['freq'] = freq_loss_val
                
                # Style-Structure Loss (requires noisy_latents and timesteps)
                # åº”ç”¨æ—¶é—´æ­¥æ„ŸçŸ¥æƒé‡ç¼©æ”¾
                style_loss_val = 0.0
                if style_loss_fn and args.lambda_style > 0:
                    style_loss = style_loss_fn(model_pred, target_velocity, noisy_latents, timesteps, num_train_timesteps=1000)
                    style_scale = ts_weights['lambda_style_scale'] if ts_weights else 1.0
                    loss = loss + args.lambda_style * style_scale * style_loss
                    style_loss_val = style_loss.item()
                loss_components['style'] = style_loss_val
                
                # === RAFT: L2 æ··åˆæ¨¡å¼ (é”šç‚¹æµ + è‡ªç”±æµ) ===
                l2_loss_val = 0.0
                raft_mode = getattr(args, 'raft_mode', False)
                free_stream_ratio = getattr(args, 'free_stream_ratio', 0.3)
                
                if raft_mode and free_stream_ratio > 0:
                    # è‡ªç”±æµ: å…¨æ—¶é—´æ­¥å‡åŒ€éšæœºé‡‡æ ·
                    free_sigmas = torch.rand(batch_size, device=latents.device, dtype=weight_dtype)
                    # Z-Image shift å˜æ¢
                    shift = args.shift if hasattr(args, 'shift') else 3.0
                    free_sigmas = (free_sigmas * shift) / (1 + (shift - 1) * free_sigmas)
                    free_sigmas = free_sigmas.clamp(0.001, 0.999)
                    
                    # æ„é€ è‡ªç”±æµåŠ å™ª latents
                    sigma_bc = free_sigmas.view(batch_size, 1, 1, 1)
                    free_noisy = sigma_bc * noise + (1 - sigma_bc) * latents
                    free_target = noise - latents  # v-prediction
                    
                    # è‡ªç”±æµå‰å‘ä¼ æ’­ (å‚ä¸æ¢¯åº¦)
                    free_input = free_noisy.unsqueeze(2)
                    if args.gradient_checkpointing:
                        free_input.requires_grad_(True)
                    free_input_list = list(free_input.unbind(dim=0))
                    
                    free_t = 1000 * free_sigmas  # è½¬å› timestep
                    free_t_norm = (1000 - free_t) / 1000.0
                    free_t_norm = free_t_norm.to(dtype=weight_dtype)
                    
                    free_pred_list = transformer(
                        x=free_input_list,
                        t=free_t_norm,
                        cap_feats=vl_embed,
                    )[0]
                    
                    free_pred = torch.stack(free_pred_list, dim=0).squeeze(2)
                    
                    # Z-Image output is negated (ä¸é”šç‚¹æµä¸€è‡´)
                    free_pred = -free_pred
                    
                    # è‡ªç”±æµ L2 æŸå¤± (ä¸å‚ä¸ SNR åŠ æƒ!)
                    l2_loss = F.mse_loss(free_pred, free_target)
                    l2_loss_val = l2_loss.item()
                    
                    # å¦‚æœ l2_include_anchor=Trueï¼Œé¢å¤–åœ¨é”šç‚¹ä¸Šè®¡ç®— L2
                    l2_include_anchor = getattr(args, 'l2_include_anchor', False)
                    if l2_include_anchor:
                        # é”šç‚¹ L2: ä½¿ç”¨å·²æœ‰çš„ model_pred å’Œ target_velocity
                        # æƒé‡ç”± l2_anchor_ratio æ§åˆ¶
                        l2_anchor_ratio = getattr(args, 'l2_anchor_ratio', 0.3)
                        anchor_l2 = F.mse_loss(model_pred, target_velocity)
                        l2_loss = l2_loss + (l2_anchor_ratio * anchor_l2)
                        l2_loss_val = l2_loss.item()
                        
                loss_components['L2'] = l2_loss_val
                
                # === SNR åŠ æƒç­–ç•¥ (v2 åä½œæ¶æ„) ===
                # å¯¹é”šç‚¹æµæŸå¤± (L1+Freq+Style) å’Œè‡ªç”±æµ L2 ç»Ÿä¸€åº”ç”¨ SNR åŠ æƒ
                # è¿™ç¡®ä¿äº†é«˜å™ªåŒºä¸ä¼šè¢« L2 ä¸»å¯¼ï¼Œé”šç‚¹çº¦æŸä¿æŒæœ‰æ•ˆ
                
                snr_weights = compute_snr_weights(
                    timesteps=timesteps,  # é”šç‚¹æµçš„ timesteps
                    num_train_timesteps=1000,
                    snr_gamma=args.snr_gamma,
                    snr_floor=args.snr_floor,
                    prediction_type="v_prediction",
                )
                snr_weights = snr_weights.to(device=loss.device, dtype=weight_dtype)
                snr_mean = snr_weights.mean()
                
                # é”šç‚¹æµæŸå¤±åŠ æƒ
                anchor_loss_weighted = loss * snr_mean
                
                # è‡ªç”±æµ L2 ä¸åŠ  SNR æƒé‡ï¼ˆè®¾è®¡æ„å›¾ï¼šL2 åªåŒºåˆ†æ˜¯å¦åŒ…å«é”šç‚¹ï¼‰
                if l2_loss_val > 0:
                    loss = anchor_loss_weighted + current_l2_ratio * l2_loss
                else:
                    loss = anchor_loss_weighted
                
                # NaN check
                if torch.isnan(loss) or torch.isinf(loss):
                    logger.warning(f"[NaN] Loss is NaN/Inf at step {global_step}, skipping backward. Components: {loss_components}")
                    optimizer.zero_grad()
                    continue
                
                # === Curvature Penalty (æ›²ç‡æƒ©ç½š) ===
                # é¼“åŠ±ç›¸é‚»é”šç‚¹é—´åšåŒ€é€Ÿç›´çº¿è¿åŠ¨ï¼Œå‡å°‘è·³è·ƒè¯¯å·®
                curvature_loss_val = 0.0
                # æ›´æ–° micro-step è®¡æ•°å™¨ï¼ˆæ¯ä¸ªå®é™… batch +1ï¼‰
                micro_step += 1
                
                if (getattr(args, 'enable_curvature', False) and 
                    args.lambda_curvature > 0 and
                    epoch >= getattr(args, 'curvature_start_epoch', 0) and
                    micro_step % getattr(args, 'curvature_interval', 10) == 0):
                    
                    # è·å–å½“å‰é”šç‚¹ç´¢å¼•å’Œ sigma
                    anchor_sigmas = acrf_trainer.anchor_sigmas  # å®é™…é”šç‚¹ sigma å€¼
                    current_sigma = timesteps.float() / 1000.0  # å½“å‰é‡‡æ ·çš„ sigma
                    
                    # åŠ¨æ€è®¡ç®— dtï¼šä½¿ç”¨å®é™…é”šç‚¹é—´è·ï¼ˆè‡ªåŠ¨é€‚åº”ä¸åŒæ­¥æ•°å’Œ shiftï¼‰
                    # ä½¿ç”¨å¹³å‡é”šç‚¹é—´è·ä½œä¸º dt
                    num_anchors = len(anchor_sigmas)
                    if num_anchors > 1:
                        # è®¡ç®—å¹³å‡é—´è·ï¼ˆè€ƒè™‘ shift å˜æ¢åçš„éå‡åŒ€åˆ†å¸ƒï¼‰
                        dt = (anchor_sigmas[0] - anchor_sigmas[-1]).abs().item() / (num_anchors - 1)
                    else:
                        dt = 0.1  # å›é€€é»˜è®¤å€¼
                    
                    sigma_plus = (current_sigma + dt).clamp(0.001, 0.999)
                    sigma_minus = (current_sigma - dt).clamp(0.001, 0.999)
                    
                    # æ„é€  t+dt å’Œ t-dt çš„åŠ å™ª latents
                    sigma_plus_bc = sigma_plus.view(batch_size, 1, 1, 1)
                    sigma_minus_bc = sigma_minus.view(batch_size, 1, 1, 1)
                    
                    noisy_plus = sigma_plus_bc * noise + (1 - sigma_plus_bc) * latents
                    noisy_minus = sigma_minus_bc * noise + (1 - sigma_minus_bc) * latents
                    
                    # å‰å‘ä¼ æ’­ (ä¸è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœæ˜¾å­˜)
                    with torch.no_grad():
                        # t + dt
                        input_plus = noisy_plus.to(dtype=weight_dtype).unsqueeze(2)
                        input_plus_list = list(input_plus.unbind(dim=0))
                        t_plus_norm = (1000 - sigma_plus * 1000) / 1000.0
                        t_plus_norm = t_plus_norm.to(dtype=weight_dtype)
                        pred_plus = transformer(x=input_plus_list, t=t_plus_norm, cap_feats=vl_embed)[0]
                        pred_plus = -torch.stack(pred_plus, dim=0).squeeze(2)
                        
                        # t - dt
                        input_minus = noisy_minus.to(dtype=weight_dtype).unsqueeze(2)
                        input_minus_list = list(input_minus.unbind(dim=0))
                        t_minus_norm = (1000 - sigma_minus * 1000) / 1000.0
                        t_minus_norm = t_minus_norm.to(dtype=weight_dtype)
                        pred_minus = transformer(x=input_minus_list, t=t_minus_norm, cap_feats=vl_embed)[0]
                        pred_minus = -torch.stack(pred_minus, dim=0).squeeze(2)
                    
                    # è®¡ç®—æ›²ç‡ (äºŒé˜¶å·®åˆ†): curvature = v+ - 2v + v-
                    # ç†æƒ³æƒ…å†µ: curvature â‰ˆ 0 (åŒ€é€Ÿç›´çº¿è¿åŠ¨)
                    # æ–¹æ¡ˆ B: pred_plus/pred_minus æ˜¯å¸¸æ•°ï¼Œåªæœ‰ model_pred æœ‰æ¢¯åº¦
                    # ç‰©ç†æ„ä¹‰: æƒ©ç½šå½“å‰é¢„æµ‹åç¦»ç›¸é‚»æ—¶é—´æ­¥çš„çº¿æ€§æ’å€¼
                    curvature = pred_plus.detach() - 2 * model_pred + pred_minus.detach()
                    curvature_loss = (curvature ** 2).mean()
                    
                    # æ·»åŠ åˆ°æ€»æŸå¤±
                    loss = loss + args.lambda_curvature * curvature_loss
                    curvature_loss_val = curvature_loss.item()
                    last_curv_loss = curvature_loss_val  # æŒä¹…åŒ–ä¿å­˜
                
                loss_components['curvature'] = last_curv_loss  # ä½¿ç”¨æŒä¹…åŒ–å€¼
                
                # ç´¯ç§¯ loss ç”¨äºå¹³å‡è®¡ç®—ï¼ˆTensorBoard æ ‡å‡†åšæ³•ï¼‰
                accumulated_loss += loss.detach().float().item()
                accumulated_l1 += loss_components.get('l1', 0)
                accumulated_cos += loss_components.get('cosine', 0)
                accumulated_freq += loss_components.get('freq', 0)
                accumulated_style += loss_components.get('style', 0)
                accumulated_l2 += loss_components.get('L2', 0)
                accumulation_count += 1
                
                # Cast loss to float32 for stable backward
                loss = loss.float()
                
                # Backward pass with error handling
                try:
                    accelerator.backward(loss)
                except RuntimeError as e:
                    logger.error(f"[BACKWARD ERROR] Step {global_step}, Loss={loss.item():.4f}")
                    logger.error(f"  Components: {loss_components}")
                    logger.error(f"  Error: {e}")
                    # Check for OOM
                    if "out of memory" in str(e).lower():
                        logger.error("  [OOM] GPU out of memory. Try reducing batch_size or enabling blocks_to_swap.")
                    raise
                
            # æ¢¯åº¦ç´¯ç§¯å®Œæˆåæ‰§è¡Œä¼˜åŒ–æ­¥éª¤ (åœ¨ accumulate å—å¤–)
            if accelerator.sync_gradients:
                accelerator.clip_grad_norm_(trainable_params, args.max_grad_norm)
                optimizer.step()
                lr_scheduler.step()
                optimizer.zero_grad()
                
                global_step += 1
                
                # è®¡ç®—ç´¯ç§¯æœŸé—´çš„å¹³å‡ lossï¼ˆTensorBoard æ ‡å‡†åšæ³•ï¼‰
                avg_loss = accumulated_loss / max(accumulation_count, 1)
                avg_l1 = accumulated_l1 / max(accumulation_count, 1)
                avg_cos = accumulated_cos / max(accumulation_count, 1)
                avg_freq = accumulated_freq / max(accumulation_count, 1)
                avg_style = accumulated_style / max(accumulation_count, 1)
                avg_l2 = accumulated_l2 / max(accumulation_count, 1)
                
                # é‡ç½®ç´¯ç§¯å˜é‡
                accumulated_loss = 0.0
                accumulated_l1 = 0.0
                accumulated_cos = 0.0
                accumulated_freq = 0.0
                accumulated_style = 0.0
                accumulated_l2 = 0.0
                accumulation_count = 0
                
                # Update EMA lossï¼ˆä½¿ç”¨å¹³å‡å€¼ï¼‰
                if ema_loss is None:
                    ema_loss = avg_loss
                else:
                    ema_loss = ema_decay * ema_loss + (1 - ema_decay) * avg_loss
                
                # Get current learning rate
                current_lr = lr_scheduler.get_last_lr()[0]
                
                # Print progress for frontend parsing (CRITICAL: exact format required)
                # åªè®©ä¸»è¿›ç¨‹æ‰“å°æ—¥å¿—ï¼Œé¿å…å¤šå¡è®­ç»ƒæ—¶æ—¥å¿—æ··ä¹±
                if accelerator.is_main_process:
                    curv = last_curv_loss
                    print(f"[STEP] {global_step}/{max_train_steps} epoch={epoch+1}/{args.num_train_epochs} loss={avg_loss:.4f} ema={ema_loss:.4f} l1={avg_l1:.4f} cos={avg_cos:.4f} freq={avg_freq:.4f} style={avg_style:.4f} L2={avg_l2:.4f} curv={curv:.4f} lr={current_lr:.2e}", flush=True)
                
                # ========== æ­£åˆ™è®­ç»ƒæ­¥éª¤ (æŒ‰æ¯”ä¾‹æ‰§è¡Œ) ==========
                # æ­£åˆ™åŒ–æ­¥éª¤åœ¨ä¸»è®­ç»ƒæ­¥éª¤å®Œæˆåç‹¬ç«‹æ‰§è¡Œï¼Œä¸å‚ä¸æ¢¯åº¦ç´¯ç§¯å‘¨æœŸ
                if reg_dataloader and reg_ratio > 0:
                    # è¾¹ç•Œæ£€æŸ¥ï¼šreg_ratio åº”åœ¨ (0, 1] èŒƒå›´å†…
                    effective_reg_ratio = min(max(reg_ratio, 0.01), 1.0)
                    # æŒ‰æ¯”ä¾‹å†³å®šæ˜¯å¦æ‰§è¡Œæ­£åˆ™æ­¥éª¤ï¼šratio=0.5 è¡¨ç¤ºæ¯2æ­¥æ‰§è¡Œ1æ¬¡æ­£åˆ™
                    reg_interval = max(1, int(1.0 / effective_reg_ratio))
                    if global_step % reg_interval == 0:
                        # è·å–æ­£åˆ™ batch
                        if reg_iterator is None:
                            reg_iterator = iter(reg_dataloader)
                        try:
                            reg_batch = next(reg_iterator)
                        except StopIteration:
                            reg_iterator = iter(reg_dataloader)
                            reg_batch = next(reg_iterator)
                        
                        # æ­£åˆ™å‰å‘ä¼ æ’­ (ç‹¬ç«‹æ­¥éª¤ï¼Œä¸ä½¿ç”¨ accumulate åŒ…è£…)
                        reg_latents = reg_batch['latents'].to(accelerator.device, dtype=weight_dtype)
                        reg_vl_embed = reg_batch['vl_embed']
                        reg_vl_embed = [v.to(accelerator.device, dtype=weight_dtype) for v in reg_vl_embed]
                        
                        reg_noise = torch.randn_like(reg_latents)
                        reg_noisy, reg_t, reg_target = acrf_trainer.sample_batch(
                            reg_latents, reg_noise, jitter_scale=args.jitter_scale, use_anchor=args.enable_turbo
                        )
                        
                        reg_input = reg_noisy.unsqueeze(2)
                        if args.gradient_checkpointing:
                            reg_input.requires_grad_(True)
                        reg_input_list = list(reg_input.unbind(dim=0))
                        reg_t_norm = (1000 - reg_t) / 1000.0
                        
                        reg_pred_list = transformer(
                            x=reg_input_list,
                            t=reg_t_norm.to(dtype=weight_dtype),
                            cap_feats=reg_vl_embed,
                        )[0]
                        reg_pred = -torch.stack(reg_pred_list, dim=0).squeeze(2)
                        
                        # ç®€å• L2 æŸå¤±ï¼Œä¿æŒæ¨¡å‹åŸæœ‰èƒ½åŠ›
                        reg_loss = F.mse_loss(reg_pred, reg_target) * reg_weight
                        reg_loss = reg_loss.float()  # ä¸ä¸»æŸå¤±ä¸€è‡´ï¼Œä½¿ç”¨ float32 åå‘ä¼ æ’­
                        
                        # ç‹¬ç«‹çš„ä¼˜åŒ–æ­¥éª¤ (ä¸å‚ä¸æ¢¯åº¦ç´¯ç§¯)
                        accelerator.backward(reg_loss)
                        accelerator.clip_grad_norm_(trainable_params, args.max_grad_norm)
                        optimizer.step()
                        lr_scheduler.step()  # ä¿®å¤ï¼šæ­£åˆ™åŒ–æ­¥éª¤ä¹Ÿéœ€è¦æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                        optimizer.zero_grad()
        
        # Save checkpoint
        if accelerator.is_main_process and (epoch + 1) % args.save_every_n_epochs == 0:
            save_path = Path(args.output_dir) / f"{args.output_name}_epoch{epoch+1}.safetensors"
            network.save_weights(str(save_path), dtype=weight_dtype)
            logger.info(f"[SAVE] Checkpoint saved: {save_path}")
    
    # Final save
    if accelerator.is_main_process:
        final_path = Path(args.output_dir) / f"{args.output_name}_final.safetensors"
        network.save_weights(str(final_path), dtype=weight_dtype)
        logger.info(f"[SAVE] Final model saved: {final_path}")
    
    logger.info("\n[DONE] Training complete!")


if __name__ == "__main__":
    main()
